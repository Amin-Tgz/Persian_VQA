\section{کار‌های مرتبط / پیش‌زمینه}
{
در سال‌های اخیر، رویکردهای بیشماری برای VQA پیشنهاد شده است. همه رویکردهای موجود شامل موارد زیر است:
	\begin{enumerate}
		\item رویکردهای مبتنی بر ترکیب ویژگی
		\item رویکردهای مبتنی بر attention
		\item رویکرد های مبتنی بر استدلال 
	\end{enumerate}
در این پروژه ما از سه روش استفاده کرده‌ایم که روش
	\lr{LSTM Q + norm I}
	 مبتنی بر ترکیب ویژگی هاست و دو روش 
	\lr{Stacked Attention Network}
	و
	\lr{HieCoAttention}
	 مبتنی بر attention‌ هستند. بر این اساس، کارهای انجام شده در این دو دسته را مرور خواهیم کرد.
	 
	 \subsection{رویکردهای مبتنی بر ترکیب ویژگی}
	 {
	 	این رویکردها هم ویژگی‌های تصویری و هم ویژگی‌های سوال را به یک فضای مشترک برای پیش‌بینی پاسخ منتقل می‌کنند. برای استخراج ویژگی‌های تصاویر، اکثر الگوریتم‌ها از CNN های از قبل آموزش دیده استفاده می‌کنند که بر روی مجموعه داده ImageNet آموزش داده شده‌اند. برخی از شبکه‌های رایج عبارتند از: 
	 	\lr{GoogLeNet}\cite{szegedy2015going}
	 	 ،
	 	\lr{ResNet} \cite{he2016deep}
	 	 و 
	 	\lr{VGGNet} \cite{simonyan2014very}.
	 	  برای استخراج ویژگی‌ها از سوالات، از روش‌هایی مانند کیسه کلمات (BOW) ، GRU
	 	  \cite{cho2014learning}
	 	   و LSTM 
	 	   \cite{hochreiter1997long}
	 	   استفاده می‌شود. در این رویکرد عموماً مسئله VQA را یک مسئله طبقه‌بندی در نظر می‌گیرند و روش‌های متعددی برای ترکیب ویژگی‌های تصویر و سوال وجود دارد. بعضی از این روش‌ها ساده می‌باشند از جمله:
	 	  \lr{concatenation}
	 	  ،
	 	  \lr{elementwise addition}
	 	  ،
	 	  \lr{elementwise multiplication}
	 	  و
	 	  \lr{bilinear pooling} .
	 	  اما ممکن است از روش‌های پیچیده‌تری مانند
	 	  \lr{Bayesian models}
	 	     نیز استفاده شود. دقتی که از روش‌های مبتنی بر این رویکرد بدست می‌آید متفاوت است و وابستگی زیادی به انتخاب هایپرپارامترها، پیکربندی سیستم و تنظیمات آزمایش‌ها دارد.
	 	  
	 }
 
 	\subsection{رویکردهای مبتنی بر attention}
	{
		 مدل‌های مبتنی بر attention به ناحیه‌هایی از تصاویر که مربوط به سوال است، توجه می‌کنند. مدل‌های موجود در این رویکرد یا به تصویر و یا به سوال و یا به هر دو توجه می‌کنند. به عنوان مثال، در
		 \cite{shih2016look}
		 مدلی را پیشنهاد داده است که با انتخاب یک منطقه تصویری که مربوط به متن سؤال باشد، پاسخ را پیش بینی می‌کند.  در این روش به به تصویر توجه شده است. اما در مثالی دیگر  
		 \cite{nguyen2018improved}
		 از چندین لایه coattention استفاده می‌کند و هر کلمه از سوال با هر منطقه در تصویر در تعامل است و بالعکس. روش‌های پیشنهادی در این رویکرد بسیار است مانند 
		 \lr{linear Attention Network (BAN)}
		 \cite{kim2018bilinear}
		  و 
		 \lr{Question Type guided Attention (QTA)}
		 \cite{shi2018question} .
	}
																																																						
}