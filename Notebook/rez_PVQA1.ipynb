{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rez_PVQA1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "m4OteN2u22vj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryamhashemi/Persian_VQA/blob/master/rez_PVQA1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBWMpHGoxrnz",
        "colab_type": "text"
      },
      "source": [
        "### Import Prerequesties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK-PVH7YP_L4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "dedf4af3-cf94-4006-c7b9-7986fbbb2c18"
      },
      "source": [
        "! pip install arabic_reshaper \n",
        "! pip install python-bidi\n",
        "!pip install deepdish\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade tables"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: arabic_reshaper in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from arabic_reshaper) (49.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from arabic_reshaper) (0.16.0)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from python-bidi) (1.15.0)\n",
            "Requirement already satisfied: deepdish in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepdish) (1.4.1)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from deepdish) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepdish) (1.19.1)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables->deepdish) (2.7.1)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.19.1)\n",
            "Requirement already up-to-date: tables in /usr/local/lib/python3.6/dist-packages (3.6.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.19.1)\n",
            "Requirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6bRyFIkFhGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os,h5py\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import deepdish as dd\n",
        "from PIL import Image\n",
        "import arabic_reshaper\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from bidi.algorithm import get_display\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Multiply, Input\n",
        "\n",
        "import random as python_random\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from tensorflow.keras.callbacks import EarlyStopping \n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOGILD3IxLAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "320a2a41-6eb6-43de-ce26-598c2f86242a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-5xC8j0y1xk",
        "colab_type": "text"
      },
      "source": [
        "### Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVebfTOqy64y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DROPOUT_RATE = 0.5\n",
        "EMBEDDING_DIM = 300\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 256\n",
        "SEQ_LENGTH = 26 #100\n",
        "VOCAB_SIZE = 1000\n",
        "OOV_TOK = \"<OOV>\"\n",
        "\n",
        "BASE_PATH = '/content/drive/My Drive/Persian_VQA/dataset/'\n",
        "QUESTION_TRAIN_PATH =   os.path.join(BASE_PATH, 'OpenEnded_mscoco_train2014_questions.json')\n",
        "ANNOTATION_TRAIN_PATH = os.path.join(BASE_PATH, 'mscoco_train2014_annotations.json')\n",
        "# IMAGE_TRAIN_PATH = os.path.join(BASE_PATH, 'train_images_1000')\n",
        "IMAGE_TRAIN_PATH = os.path.join('/content/', 'train')\n",
        "\n",
        "QUESTION_VAL_PATH =   os.path.join(BASE_PATH, 'OpenEnded_mscoco_val2014_questions.json')\n",
        "ANNOTATION_VAL_PATH = os.path.join(BASE_PATH, 'mscoco_val2014_annotations.json')\n",
        "# IMAGE_VAL_PATH = os.path.join(BASE_PATH, 'val_images_500')\n",
        "IMAGE_VAL_PATH = os.path.join('/content/', 'val')\n",
        "\n",
        "QUESTION_TEST_PATH =   os.path.join(BASE_PATH, '...')\n",
        "ANNOTATION_TEST_PATH = os.path.join(BASE_PATH, '...')\n",
        "# IMAGE_TEST_PATH = os.path.join(BASE_PATH, 'val_images_500')\n",
        "IMAGE_TEST_PATH = os.path.join('/content/', 'test')\n",
        "\n",
        "NUM_OF_CLASSES=1000\n",
        "NUM_OF_MOST_COMMON_ANSWERS = 999\n",
        "BASE_PATH_parssoft = '/content/drive/My Drive/parssoftco_PVQA/'\n",
        "BASE_PATH_parssoft2 = '/content/drive/My Drive/parssoftco_PVQA2/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJg7-dXsa8i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "from zipfile import ZipFile\n",
        "# #If the downloaded file is a zip file than you can use below function to unzip it.\n",
        "def unzip(dir,where):\n",
        "    with ZipFile(dir) as zipf:\n",
        "        zipf.extractall(where)\n",
        "    print(\"File Unzipped!\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwVaZ7a18Ovv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0a9183b8-c564-4223-b6fb-91042cdbce44"
      },
      "source": [
        "!wget https://filebox.ece.vt.edu/~jiasenlu/codeRelease/vqaRelease/train_only/data_train_val.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-03 00:51:52--  https://filebox.ece.vt.edu/~jiasenlu/codeRelease/vqaRelease/train_only/data_train_val.zip\n",
            "Resolving filebox.ece.vt.edu (filebox.ece.vt.edu)... 128.173.88.43\n",
            "Connecting to filebox.ece.vt.edu (filebox.ece.vt.edu)|128.173.88.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 716074236 (683M) [application/zip]\n",
            "Saving to: ‘data_train_val.zip’\n",
            "\n",
            "data_train_val.zip  100%[===================>] 682.90M  23.9MB/s    in 29s     \n",
            "\n",
            "2020-08-03 00:52:22 (23.2 MB/s) - ‘data_train_val.zip’ saved [716074236/716074236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPMm3M5tzc3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3e673a1-42ce-4c62-f5a4-4b5b67229c83"
      },
      "source": [
        "unzip('/content/data_train_val.zip',BASE_PATH_parssoft)#drive/My Drive/Persian_VQA/\n",
        "#data_img.h5 data_prepro.h5 data_prepro.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Unzipped!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqyLy7lGxky7",
        "colab_type": "text"
      },
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFFjq4jWHgKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def most_common_answer_from_train(answers,num_of_common_answers):\n",
        "  counts = {}\n",
        "  for ans in answers:\n",
        "      counts[ans] = counts.get(ans,0) + 1\n",
        "  counter = sorted([(count,w) for w,count in counts.items()], reverse=True)\n",
        "  most_common_vocab = []\n",
        "  for i in range(num_of_common_answers):\n",
        "      most_common_vocab.append(counter[i][1])\n",
        "  return most_common_vocab"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFw0Yqw8NWJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_dataset(qus, ann, answertoindex):\n",
        "  qs = []\n",
        "  # raw_answers = []\n",
        "  answers = []\n",
        "  qs_id = []\n",
        "  im_id = []\n",
        "\n",
        "  # ann2=ann\n",
        "  # for ann in ann['annotations']:\n",
        "  #   raw_answers.append(ann['multiple_choice_answer'])\n",
        "  # most_common_answers = most_common_answer_from_train(raw_answers,NUM_OF_MOST_COMMON_ANSWERS)\n",
        "  # answertoindex = {w:i+1 for i,w in enumerate(most_common_answers)}\n",
        "  # indextoanswer = {i+1:w for i,w in enumerate(most_common_answers)}\n",
        "\n",
        "  filtered_train_question_ids={}\n",
        "  # ann=ann2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  i=0\n",
        "  for ann in ann['annotations']:\n",
        " \n",
        "    if ann['multiple_choice_answer'] in answertoindex.keys():\n",
        "      answers.append(ann['multiple_choice_answer'])\n",
        "      # filtered_train_question_ids.append(ann['question_id'])\n",
        "      filtered_train_question_ids[ann['question_id']]=1\n",
        "      # if(i%1000==0):print(i)\n",
        "      i+=1\n",
        "\n",
        "  for q in qus['questions']:\n",
        "    if q['question_id'] in filtered_train_question_ids.keys():\n",
        "      qs.append(q['question'])\n",
        "      qs_id.append(q['question_id'])\n",
        "      im_id.append(q['image_id'])\n",
        "\n",
        "\n",
        "  return qs, answers, qs_id, im_id"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJBqQMXBwtuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(qus, ann):\n",
        "  qs = []\n",
        "  raw_answers = []\n",
        "  answers = []\n",
        "  qs_id = []\n",
        "  im_id = []\n",
        " \n",
        "\n",
        "  for q in qus['questions']:\n",
        "    qs.append(q['question'])\n",
        "    qs_id.append(q['question_id'])\n",
        "    im_id.append(q['image_id'])\n",
        "\n",
        "  for ann in ann['annotations']:\n",
        "    answers.append(ann['multiple_choice_answer'])\n",
        "\n",
        "\n",
        "  return qs, answers, qs_id, im_id"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTqIiXJnK6Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_dataset():\n",
        "  qs = json.load( open(QUESTION_TRAIN_PATH))\n",
        "  ann = json.load( open(ANNOTATION_TRAIN_PATH))\n",
        "\n",
        "  original_ann = ann\n",
        "  raw_answers = []\n",
        "  for ann in ann['annotations']:\n",
        "    raw_answers.append(ann['multiple_choice_answer'])\n",
        "  most_common_answers = most_common_answer_from_train(raw_answers,NUM_OF_MOST_COMMON_ANSWERS)\n",
        "  answertoindex = {w:i for i,w in enumerate(most_common_answers)}#i+1\n",
        "  indextoanswer = {i:w for i,w in enumerate(most_common_answers)}#i+1\n",
        "\n",
        "  qs, answers, qs_id, im_id=create_train_dataset(qs, original_ann, answertoindex)\n",
        "\n",
        "  return qs, answers, qs_id, im_id,answertoindex,indextoanswer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jenrLGl03rdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_val_dataset():\n",
        "  qs = json.load( open(QUESTION_VAL_PATH))\n",
        "  ann = json.load( open(ANNOTATION_VAL_PATH))\n",
        "  \n",
        "  return create_dataset(qs, ann)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ6eQ8HOPI1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_dataset():\n",
        "  qs = json.load( open(QUESTION_TEST_PATH))\n",
        "  # ann = json.load( open(ANNOTATION_TRAIN_PATH))\n",
        "  \n",
        "  return create_dataset(ims, qs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2zFZ8s2Wp2p",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV5MQ5WE_E0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_visualqa(qs, answer, image):\n",
        "  im = Image.open(image)  \n",
        "  plt.figure()\n",
        "  plt.imshow(im)\n",
        "  title = arabic_reshaper.reshape(qs + \"\\n\" + answer)\n",
        "  title = get_display(title) \n",
        "  plt.title(title)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def visualize_train(num):\n",
        "  show_visualqa(train_qs[num], train_answers[num], ims.get(train_image_ids[num]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aZM3F6EH3PE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "599c7f49-8e7c-435b-91a9-06e61087b3eb"
      },
      "source": [
        "train_qs, train_answers, train_q_ids, train_image_ids, answertoindex, indextoanswer = get_train_dataset()\n",
        "val_qs, val_answers, val_q_ids, val_image_ids = get_val_dataset()\n",
        "# test_qs, test_answers, test_q_ids, test_image_ids = get_test_dataset()\n",
        "\n",
        "print('train : ')\n",
        "print(len(train_qs))\n",
        "print(len(train_answers))\n",
        "print(len(train_q_ids))\n",
        "print(len(train_image_ids))\n",
        "\n",
        "print('val : ')\n",
        "print(len(val_qs))\n",
        "print(len(val_answers))\n",
        "print(len(val_q_ids))\n",
        "print(len(val_image_ids))\n",
        "\n",
        "# print(len(test_qs))\n",
        "# print(len(test_answers))\n",
        "# print(len(test_q_ids))\n",
        "# print(len(test_image_ids))\n",
        "\n",
        "#train : 215359   val: 121512\n",
        "#train : 215375   val: 121512 ours"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train : \n",
            "215359\n",
            "215359\n",
            "215359\n",
            "215359\n",
            "val : \n",
            "121512\n",
            "121512\n",
            "121512\n",
            "121512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57AwOi1kuM70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a09b1a8f-d9bd-4fd6-f535-006d0448efde"
      },
      "source": [
        "train_answers.count('business')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj-8mSzw3--x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZbz7iQUDs7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "542168f8-1f68-4405-fb85-894a88de16e5"
      },
      "source": [
        "li=[]\n",
        "for t in train_qs:\n",
        "  li.append(len(t))\n",
        "question_max_len=np.max(li)\n",
        "print(question_max_len)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbQPIR7ANpjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ims = get_train_image_paths()\n",
        "# visualize_train(0)\n",
        "# visualize_train(2200)\n",
        "# visualize_train(600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlzDNNBr7RIh",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare questions to feed into network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z_h_urH1Y31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6c2e523e-11b0-4960-f07d-415c2ca69659"
      },
      "source": [
        "!wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-01 00:01:12--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.16MB/s    in 6m 26s  \n",
            "\n",
            "2020-08-01 00:07:38 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3dTQ7MhRyeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "26c0bb0e-7b96-410f-f1b7-d78c54f80515"
      },
      "source": [
        "# !unzip /content/glove.6B.zip\n",
        "unzip('/content/glove.6B.zip','/content/drive/My Drive/parssoftco_PVQA/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "File Unzipped!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGzP7nNujxhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "vocab_and_vectors = {}\n",
        "file = open(BASE_PATH_parssoft+'glove.6B.300d.txt')\n",
        "for line in (file):\n",
        "    value = line.split(' ')\n",
        "    word = value[0]\n",
        "    coef = np.array(value[1:],dtype = 'float32')\n",
        "    vocab_and_vectors[word] = coef\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve6QIMugr6_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "# get the vectors\n",
        "file = gzip.open(urlopen('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ro.300.vec.gz'))\n",
        "# https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "# Now let’s prepare this file for vector extraction.\n",
        "\n",
        "vocab_and_vectors = {}\n",
        "# put words as dict indexes and vectors as words values\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values [0].decode('utf-8')\n",
        "  vector = np.asarray(values[1:], dtype='float32')\n",
        "  vocab_and_vectors[word] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY2avJ7xexoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dd.io.save(BASE_PATH_parssoft +'fasttext-en-300.h5', vocab_and_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwsFvm_QqqVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#persian fasttext\n",
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "# get the vectors\n",
        "file_fa = gzip.open(urlopen('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.vec.gz'))\n",
        "# https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fa.300.bin.gz\n",
        "# Now let’s prepare this file for vector extraction.\n",
        "\n",
        "\n",
        "\n",
        "# import codecs\n",
        "# f = codecs.open('unicode.rst', encoding='utf-8')\n",
        "# for line in f:\n",
        "#     print (repr(line))\n",
        "\n",
        "vocab_and_vectors_fa = {}\n",
        "# put words as dict indexes and vectors as words values\n",
        "for line in file_fa:\n",
        "  values = line.split()\n",
        "  # print(values)\n",
        "  word = values [0].decode('utf-8')\n",
        "  vector = np.asarray(values[1:], dtype='float32')\n",
        "  vocab_and_vectors_fa[word] = vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8teUMJy7aWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_words = VOCAB_SIZE,\n",
        "\n",
        "# !\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n\n",
        "tokenizer = Tokenizer(oov_token=OOV_TOK)#filters=\"-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=\"\n",
        "tokenizer.fit_on_texts(train_qs)\n",
        "\n",
        "train_X_seqs = tokenizer.texts_to_sequences(train_qs)\n",
        "val_X_seqs = tokenizer.texts_to_sequences(val_qs)\n",
        "# test_X_seqs = tokenizer.texts_to_sequences(test_qs)\n",
        "\n",
        "train_X_seqs = pad_sequences(train_X_seqs, maxlen=SEQ_LENGTH, padding='pre')#post\n",
        "val_X_seqs = pad_sequences(val_X_seqs, maxlen=SEQ_LENGTH, padding='pre')#post\n",
        "# test_X_seqs = pad_sequences(test_X_seqs, maxlen=SEQ_LENGTH, padding='post')\n",
        "\n",
        "train_X_seqs = np.array(train_X_seqs)\n",
        "val_X_seqs = np.array(val_X_seqs)\n",
        "# test_X_seqs = np.array(test_X_seqs)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyKKCnmGnGH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_X_seqs = [word_tokenize(i) for i in train_qs]\n",
        "# val_X_seqs = [word_tokenize(i) for i in val_qs]\n",
        "\n",
        "# all_words = []\n",
        "# for sent in train_qs:\n",
        "#     tokenize_word = word_tokenize(sent)\n",
        "#     for word in tokenize_word:\n",
        "#         all_words.append(word)\n",
        "# from keras.preprocessing.text import one_hot\n",
        "# embedded_sentences = [one_hot(sent, 13447) for sent in train_qs]\n",
        "# print(embedded_sentences[0] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-3CwheBNTV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def right_align(seq,lengths):\n",
        "    v = np.zeros(np.shape(seq))\n",
        "    N = np.shape(seq)[1]\n",
        "    for i in range(np.shape(seq)[0]):\n",
        "        v[i][N-lengths[i]:N]=seq[i][0:lengths[i]]\n",
        "    return v"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERvAF5fhXyCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e001bd4d-1307-4377-db8b-d79890cd62c6"
      },
      "source": [
        "ques_data = h5py.File(BASE_PATH_parssoft + 'data_prepro.h5')\n",
        "ques_answers = np.array(ques_data['answers'])[:]\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-452d394de588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mques_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH_parssoft\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data_prepro.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mques_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mques_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'h5py' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaSsNE_nYIFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "ddafda6f-fafd-4bab-c6a7-6828bc226c2a"
      },
      "source": [
        "ques_answers.shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-985721a88fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mques_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ques_answers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvMvhCiWhr3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "56fb2278-2220-44f8-a1e3-a2d59a1bb512"
      },
      "source": [
        "qss_train = json.load( open(QUESTION_TRAIN_PATH))\n",
        "qss_val = json.load( open(QUESTION_VAL_PATH))\n",
        "ques_data = h5py.File(BASE_PATH_parssoft + 'data_prepro.h5')\n",
        "qid_to_tokens_train={}\n",
        "\n",
        "ques_train = np.array(ques_data['ques_train'])[:, :]\n",
        "ques_length_train = np.array(ques_data['ques_length_train'])[:]\n",
        "ques_train = right_align(ques_train, ques_length_train)\n",
        "qids_train=ques_data['question_id_train'][:]\n",
        "qid_to_tokens_train={}\n",
        "for i,q in enumerate(ques_train):\n",
        "  qid_to_tokens_train[qids_train[i]]=q\n",
        "\n",
        "ques_val = np.array(ques_data['ques_test'])[:, :]\n",
        "ques_length_val = np.array(ques_data['ques_length_test'])[:]\n",
        "ques_val = right_align(ques_val, ques_length_val)\n",
        "\n",
        "for _ in ques_val:\n",
        "    if 12602 in _:\n",
        "        _[_==12602] = 0\n",
        "\n",
        "qids_val=ques_data['question_id_test'][:]\n",
        "qid_to_tokens_val={}\n",
        "for i,q in enumerate(ques_val):\n",
        "  qid_to_tokens_val[qids_val[i]]=q\n",
        "\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq-v9MMbyNMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X_seqs = np.array([qid_to_tokens_train[id] for id in train_q_ids])\n",
        "val_X_seqs = np.array([qid_to_tokens_val[id] for id in val_q_ids])\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b8_Sbk303Dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_metadata():\n",
        "    meta_data = json.load(open(BASE_PATH_parssoft+'data_prepro.json', 'r'))\n",
        "    meta_data['ix_to_word'] = {str(word):int(i) for i,word in meta_data['ix_to_word'].items()}\n",
        "    return meta_data\n",
        "\n",
        "metadata = get_metadata()\n",
        "num_classes = len(metadata['ix_to_ans'].keys())\n",
        "num_words = len(metadata['ix_to_word'].keys())\n",
        "\n",
        "# anss = len(metadata['ans_to_ix'].keys())\n",
        "\n",
        "# embedding_matrix = np.zeros((num_words, 300))\n",
        "word_index = metadata['ix_to_word']\n",
        "\n",
        "# for word, i in word_index.items():\n",
        "#     embedding_vector = vocab_and_vectors.get(word)\n",
        "#     if embedding_vector is not None:\n",
        "#         embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "# print(num_classes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTU8Lnzacnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bed15016-6a97-445b-b69d-e1a1c90c17e0"
      },
      "source": [
        "metadata['ix_to_ans'].keys()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '725', '726', '727', '728', '729', '730', '731', '732', '733', '734', '735', '736', '737', '738', '739', '740', '741', '742', '743', '744', '745', '746', '747', '748', '749', '750', '751', '752', '753', '754', '755', '756', '757', '758', '759', '760', '761', '762', '763', '764', '765', '766', '767', '768', '769', '770', '771', '772', '773', '774', '775', '776', '777', '778', '779', '780', '781', '782', '783', '784', '785', '786', '787', '788', '789', '790', '791', '792', '793', '794', '795', '796', '797', '798', '799', '800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '813', '814', '815', '816', '817', '818', '819', '820', '821', '822', '823', '824', '825', '826', '827', '828', '829', '830', '831', '832', '833', '834', '835', '836', '837', '838', '839', '840', '841', '842', '843', '844', '845', '846', '847', '848', '849', '850', '851', '852', '853', '854', '855', '856', '857', '858', '859', '860', '861', '862', '863', '864', '865', '866', '867', '868', '869', '870', '871', '872', '873', '874', '875', '876', '877', '878', '879', '880', '881', '882', '883', '884', '885', '886', '887', '888', '889', '890', '891', '892', '893', '894', '895', '896', '897', '898', '899', '900', '901', '902', '903', '904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919', '920', '921', '922', '923', '924', '925', '926', '927', '928', '929', '930', '931', '932', '933', '934', '935', '936', '937', '938', '939', '940', '941', '942', '943', '944', '945', '946', '947', '948', '949', '950', '951', '952', '953', '954', '955', '956', '957', '958', '959', '960', '961', '962', '963', '964', '965', '966', '967', '968', '969', '970', '971', '972', '973', '974', '975', '976', '977', '978', '979', '980', '981', '982', '983', '984', '985', '986', '987', '988', '989', '990', '991', '992', '993', '994', '995', '996', '997', '998', '999', '1000'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkjjxx9fbQrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95b86bcf-1509-4f4b-dec5-cded4047ea24"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9N5ZPKjyFsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_X_ims = [train_images_dict[id] for id in train_image_ids]\n",
        "# val_X_ims = [val_images_dict[id] for id in val_image_ids]\n",
        "# train_X_ims = np.array(train_X_ims)\n",
        "# val_X_ims = np.array(val_X_ims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yxOUW-smw7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "  print(word,i)\n",
        "  # embedding_vector = vocab_and_vectors_fa.get(word)\n",
        "  # embedding_vector = vocab_and_vectors.get(word)\n",
        "  embedding_vector = vocab_and_vectors.get(word) #glove\n",
        "  \n",
        "\n",
        "  # words that cannot be found will be set to 0\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr33UAajSkG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix[60]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7PcayZPmqio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(BASE_PATH_parssoft + 'embedding_matrix_glove_d300_l26_prepad',embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_Dn94zdm2t9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix=np.load(BASE_PATH_parssoft + 'embedding_matrix_glove_d300_l26.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQMuaSbV0QNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(BASE_PATH_parssoft + 'embedding_matrix_glove_d300_l26_prepad_originalpaper',embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X7Yf95-2Wiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix=np.load(BASE_PATH_parssoft + 'embedding_matrix_glove_d300_l26_prepad_originalpaper.npy')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrMIOnHy7bdA",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare images to feed into network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iST5QjfB9-iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG19 tra\n",
        "train_images_dict = dd.io.load('/content/drive/My Drive/parssoftco_PVQA/rez_vgg19_features/X_train_ims_VGG19.h5')\n",
        "val_images_dict = dd.io.load('/content/drive/My Drive/parssoftco_PVQA/rez_vgg19_features/X_val_ims_VGG19.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM6YU7FwI2Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG19 pre\n",
        "train_images_dict = dd.io.load(BASE_PATH_parssoft+'train_imid_to_feats_dict.h5')\n",
        "val_images_dict = dd.io.load(BASE_PATH_parssoft+'val_imid_to_feats_dict.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Etepo_pK0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1a52dfe0-d5a8-4ba1-cc2e-bbf0033a279e"
      },
      "source": [
        "# qss_train = json.load( open(QUESTION_TRAIN_PATH))\n",
        "# qss_val = json.load( open(QUESTION_VAL_PATH))\n",
        "# qid_to_imid_train={}\n",
        "# for q in qss_train['questions']:\n",
        "#   qid_to_imid_train[q['question_id']]=q['image_id']\n",
        "# qid_to_imid_val={}\n",
        "# for q in qss_val['questions']:\n",
        "#   qid_to_imid_val[q['question_id']]=q['image_id']\n",
        "\n",
        "##\n",
        "#features of VGG19\n",
        "# img_data = h5py.File('data_img.h5')\n",
        "# ques_data = h5py.File('data_prepro.h5')\n",
        "\n",
        "# img_data_train = np.array(img_data['images_train'])\n",
        "# img_pos_train = ques_data['img_pos_train'][:]\n",
        "# qids_train=ques_data['question_id_train'][:]\n",
        "# train_img_data = np.array([img_data_train[_-1,:] for _ in img_pos_train])\n",
        "# img_features_dict_train={}\n",
        "# for i,q in enumerate(qids_train):\n",
        "#   if not qid_to_imid_train[q] in img_features_dict_train:\n",
        "#     img_features_dict_train[qid_to_imid_train[q]]=train_img_data[i-1]\n",
        "\n",
        "# img_data_val = np.array(img_data['images_test'])\n",
        "# img_pos_val = ques_data['img_pos_test'][:]\n",
        "# qids_val=ques_data['question_id_test'][:]\n",
        "# val_img_data = np.array([img_data_val[_-1,:] for _ in img_pos_val])\n",
        "# img_features_dict_val={}\n",
        "# for i,q in enumerate(qids_val):\n",
        "#   if not qid_to_imid_val[q] in img_features_dict_val:\n",
        "#     img_features_dict_val[qid_to_imid_val[q]]=val_img_data[i-1]\n",
        "\n",
        "# # dd.io.save(BASE_PATH_parssoft+'train_imid_to_feats_dict.h5',img_features_dict_train)\n",
        "# # dd.io.save(BASE_PATH_parssoft+'val_imid_to_feats_dict.h5',img_features_dict_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RELjtuYPpPvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tem = np.sqrt(np.sum(np.multiply(val_X_ims, val_X_ims), axis=1))\n",
        "t=np.tile(tem,(4096,1))\n",
        "val_X_ims = np.divide(val_X_ims, np.transpose(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRoYCSV2tZNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tem = np.sqrt(np.sum(np.multiply(train_X_ims, train_X_ims), axis=1))\n",
        "t=np.tile(tem,(4096,1))\n",
        "train_X_ims = np.divide(train_X_ims, np.transpose(t))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO9LTTruMo9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X_ims = [train_images_dict[id] for id in train_image_ids]\n",
        "val_X_ims = [val_images_dict[id] for id in val_image_ids]\n",
        "train_X_ims = np.array(train_X_ims)\n",
        "val_X_ims = np.array(val_X_ims)\n",
        "\n",
        "tem = np.sqrt(np.sum(np.multiply(train_X_ims, train_X_ims), axis=1))\n",
        "train_X_ims = np.divide(train_X_ims, np.transpose(np.tile(tem,(4096,1))))\n",
        "\n",
        "# tem = np.sqrt(np.sum(np.multiply(val_X_ims, val_X_ims), axis=1))\n",
        "# val_X_ims = np.divide(val_X_ims, np.transpose(np.tile(tem,(4096,1))))\n",
        "\n",
        "train_images_dict =0\n",
        "val_images_dict =0\n",
        "train_ims =None\n",
        "val_ims =None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axsQ85wULHCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save( 'train_X_ims_pre_l2.npy',train_X_ims)\n",
        "# np.save('val_X_ims_pre_l2.npy',val_X_ims)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1BXnpvyoKTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/val_X_ims_pre_l2.npy  /content/drive/My\\ Drive/parssoftco_PVQA/val_X_ims_pre_l2.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXATIPi2Ajto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BIbe04rytTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/train_X_ims_pre_l2.npy  /content/drive/My\\ Drive/parssoftco_PVQA/train_X_ims_pre_l2.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55FZjAKdCgsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X_ims = np.load(BASE_PATH_parssoft + 'train_X_ims_pre_l2.npy')#, mmap_mode='r'\n",
        "val_X_ims = np.load(BASE_PATH_parssoft + 'val_X_ims_pre_l2.npy')#, mmap_mode='r'\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzbbhC5n8CYo",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare labels of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYl1K60q8J87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eaaeb89e-b402-45ed-f22e-83ee1cd295b3"
      },
      "source": [
        "# all_answers = get_answers(train_answers)\n",
        "# num_answers = len(all_answers)\n",
        "# num_classes = num_answers +1 \n",
        "\n",
        "train_answer_indices = []\n",
        "val_answer_indices = []\n",
        "test_answer_indices = []\n",
        "\n",
        "for ans in train_answers:\n",
        "    train_answer_indices.append(answertoindex[ans])\n",
        " \n",
        "\n",
        "for ans in val_answers:\n",
        "  if ans in answertoindex.keys():\n",
        "    val_answer_indices.append(answertoindex[ans])\n",
        "  else: \n",
        "    val_answer_indices.append('999')\n",
        "\n",
        "\n",
        "\n",
        "# for a in test_answers:\n",
        "#   if a in all_answers:\n",
        "#     test_answer_indices.append(all_answers.index(a))\n",
        "#   else:\n",
        "#     test_answer_indices.append(num_answers)\n",
        "\n",
        "train_Y = to_categorical(np.array(train_answer_indices),num_classes=999)\n",
        "val_Y = to_categorical(np.array(val_answer_indices))\n",
        "# test_Y = to_categorical(test_answer_indices)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train_Y = to_categorical(np.array(train_answers).factorize()[0])\n",
        "# val_Y = to_categorical(np.array(val_answers).factorize()[0])\n",
        "# test_Y = to_categorical(test_answer_indices)\n",
        "\n",
        "\n",
        "print(train_Y.shape)\n",
        "print(val_Y.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(215359, 999)\n",
            "(121512, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5OZxbkk9jKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "16ec744e-c5a6-49a7-d6d4-a1173f6d92ea"
      },
      "source": [
        "answertoindex.keys()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['yes', 'no', '2', '1', 'white', '3', 'red', 'blue', '4', 'green', 'black', 'yellow', 'brown', '5', 'tennis', 'baseball', 'right', 'orange', 'bathroom', 'left', '6', 'wood', 'frisbee', '0', 'pink', 'pizza', 'gray', 'kitchen', 'skateboarding', 'cat', '7', 'black and white', 'skiing', '8', 'dog', 'surfing', 'water', 'snow', 'skateboard', '10', 'wii', 'surfboard', 'man', 'kite', 'grass', 'purple', 'giraffe', 'eating', 'broccoli', 'stop', 'elephant', 'phone', 'apple', 'train', 'winter', 'umbrella', 'sheep', 'silver', 'horse', 'banana', 'motorcycle', '9', 'laptop', 'beach', 'sunny', 'cake', 'brick', 'wine', 'woman', 'hat', '12', 'bear', 'flowers', 'food', 'bananas', 'table', 'soccer', 'living room', 'female', 'bench', 'cow', 'bus', 'zebra', 'snowboarding', 'male', 'kites', '11', 'hot dog', 'tennis racket', 'trees', 'helmet', 'night', 'fence', 'teddy bear', 'down', 'tile', 'tan', 'standing', 'camera', 'airport', 'outside', 'bat', 'bird', 'donut', 'cloudy', 'bed', 'christmas', 'zoo', 'tree', 'metal', 'cheese', '20', 'bedroom', 'car', 'red and white', 'fork', 'palm', 'plane', 'cows', 'glass', 'bike', 'beer', 'chinese', 'suitcase', 'sitting', 'old', 'sandwich', 'carrots', 'boat', 'stripes', 'skis', 'blonde', 'glasses', '15', 'up', 'chocolate', 'cell phone', '13', 'nike', 'tv', 'walking', 'airplane', 'sand', 'chair', 'open', 'horses', 'birthday', 'mountains', 'fruit', 'fire hydrant', 'sunglasses', 'scissors', 'ocean', 'donuts', 'cold', 'wall', 'truck', 'tie', 'coffee', 'fall', 'many', 'girl', 'clear', 'usa', 'street', 'round', 'day', 'blue and white', 'toilet', 'plaid', 'snowboard', '25', 'cooking', 'nothing', 'ski poles', 'wedding', 'wetsuit', 'knife', 'boy', 'ball', 'breakfast', 'sleeping', 'mirror', 'asian', 'africa', 'people', 'afternoon', 'toothbrush', 'plate', 'paper', 'on table', 'elephants', 'square', 'stone', 'mountain', 'window', 'dirt', 'couch', 'clock', 'city', 'no one', 'evening', '14', 'zebras', 'happy', 'chicken', 'building', 'sun', 'backpack', 'police', 'playing wii', 'daytime', 'fish', 'luggage', 'flying kite', 'plastic', 'lot', 'spoon', 'on wall', 'park', 'england', 'remote', 'picture', 'oranges', 'brushing teeth', 'birds', 'restaurant', 'refrigerator', 'pine', '50', 'watch', 'very', 'jeans', 'graffiti', 'brown and white', 'summer', 'rainy', 'background', 'talking on phone', 'sidewalk', 'safety', 'leaves', 'hay', 'concrete', 'carrot', '16', 'motorcycles', 'bicycle', 'american', 'none', 'in water', 'child', 'umbrellas', 'overcast', 'gold', 'giraffes', 'field', 'wii remote', 'playing tennis', 'microwave', 'catcher', 'resting', 'floor', 'towel', 'rocks', 'ground', '24', 'pepperoni', 'milk', 'london', 'coca cola', 'circle', 'books', '30', 'heart', 'floral', 'checkered', 'vegetables', 'racket', 'church', 'apples', 'tomato', 'surfboards', 'middle', 'in air', 'double decker', 'vase', 'small', 'rainbow', 'person', 'on', 'light', 'flower', 'box', 'bag', 'pitcher', 'closed', 'bridge', 'shadow', 'rain', 'new york', 'sink', 'morning', 'clouds', 'bowl', 'gas', 'umpire', 'rock', 'parking meter', 'keyboard', 'taking picture', 'grazing', 'sandals', 'inside', '100', 'striped', 'leather', 'bread', 'triangle', 'lights', 'drinking', 'baby', 'wire', 'reading', 'ketchup', 'blanket', 'salad', 'rope', 'china', 'sunset', 'purse', 'on left', 'computer', 'adidas', 'wilson', 'roses', 'road', '18', 'jumping', 'dessert', 'canada', 'bears', 'river', 'hot dogs', 'goggles', 'young', 'texting', 'hotel', 'glove', 'dell', 'skate park', 'shorts', 'passenger', 'on plate', 'house', 'electric', 'desk', 'book', '17', 'train station', 'soup', 'playing', 'photographer', 'oven', 'mouse', 'counter', 'cars', 'tracks', 'shirt', 'rose', 'red and yellow', 'rectangle', 'plant', 'olives', 'office', 'home', 'electricity', 'beige', 'windows', 'seagull', 'red and blue', 'guitar', 'gloves', 'star', 'spinach', 'shade', 'noon', 'large', 'delta', 'top', 'tennis ball', 'stop sign', 'smoke', 'wind', 'sky', 'sign', 'on ground', 'jacket', 'helmets', 'flying', 'branch', 'tabby', 'decoration', 'cutting board', 'bottom', 'tomatoes', 'tennis court', 'taking off', 'steam', 'stainless steel', 'sneakers', 'rug', 'lettuce', 'cup', 'basket', 'short', 'lemon', 'jet', 'indoors', 'head', 'both', 'wii controller', 'toy', 'stove', 'real', 'orange juice', 'oak', 'mustard', 'lab', 'clay', 'calm', 'blinds', 'white and blue', 'trash can', 'toilet paper', 'red and black', 'peppers', 'long', 'hot', 'hand', 'flag', 'fan', 'spring', 'ski', 'shoes', 'ponytail', 'fire', 'blue and yellow', '40', 'water skiing', 'urban', 'swimming', 'school', 'samsung', 'protection', 'pictures', 'pepsi', 'parking', 'on desk', 'market', 'flip flops', 'tea', 'talking', 'suit', 'scarf', 'posing', 'polar', 'on bed', 'landing', 'english', 'diamond', 'collar', 'at camera', 'trash', 'raining', 'parrot', 'oval', 'laying down', 'good', 'bricks', 'boats', 'away', 'shelf', 'running', 'rice', 'pole', 'meat', 'lake', 'india', 'fridge', 'fork and knife', 'clothes', 'carpet', 'unknown', 'turkey', 'straw', 'playing frisbee', 'parasailing', 'lamp', 'cross', 'color', 'chef', 'bottle', 'boots', 'yellow and blue', 'strawberries', 'skateboards', 'polo', 'orange and white', 'one way', 'headphones', 'balance', 'strawberry', 'steel', 'p', 'octagon', 'military', 'headband', 'front', 'fries', 'dogs', 'dinner', 'bicycles', '19', 'skateboarder', 'pillow', 'parking lot', 'parade', 'napkin', 'flying kites', 'cutting cake', 'cowboy', 'blender', 'bikes', '23', 'shower', 'ring', 'pug', 'polar bear', 'on sidewalk', 'mercedes', 'japan', 'hydrant', 'granite', 'german', 'dirty', 'cutting', 'collie', 'carriage', 'asia', '2 feet', 'tower', 'soda', 'reflection', 'outdoors', 'off', 'ford', 'dunkin donuts', 'duck', 'coke', 'clean', 'chain link', 'beef', 'above', 'wine glass', 'surf', 'spanish', 'pen', \"mcdonald's\", 'indian', 'hit ball', 'fake', 'dusk', 'dress', 'chopsticks', 'bracelet', 'baseball bat', 'air', '22', '21', 'wool', 'w', 'ski lift', 'siamese', 'painting', 'onions', 'men', 'lighthouse', 'italy', 'ice cream', 'honda', 'gray and white', 'grapes', 'football', 'downhill', 'candles', 'bmw', '200', 'white and red', 'watching', 'seagulls', 'red white and blue', 'ramp', 'poles', 'plants', 'owl', 'nowhere', 'no parking', 'net', 'necklace', 'lunch', 'kia', 'jump', 'ham', 'green and white', 'fishing', 'fire truck', 'ducks', 'bow', 'bacon', '27', 'warm', 'tulips', 'slow', 'on floor', 'on counter', 'north', 'marble', 'in bowl', 'fedora', 'door', 'dock', 'big ben', 'batting', 'b', '3 feet', 'van', 'toyota', 'terrier', 'tennis rackets', 'stuffed animal', 'riding', 'pot', 'pepper', 'on tracks', 'krispy kreme', 'fedex', 'dodgers', 'dining room', 'crosswalk', 'cigarette', 'big', 'basketball', 'bandana', 'bakery', 'back', 'art', 'visor', 'teddy bears', 'suitcases', 'sugar', 'stairs', 'sparrow', 'shoe', 'serve', 'public', 'paint', 'newspaper', 'monkey', 'low', 'face', 'candle', 'black and red', 'apartment', 'african', 'a', '35', '28', 'wet', 'united', 'tattoo', 'statue', 'starbucks', 'sprinkles', 'sailboat', 'parsley', 'on right', 'on grass', 'log', \"i don't know\", 'hello kitty', 'go', 'giants', 'game', 'french', 'fast', 'eagle', 'children', 'cell phones', 'broken', 'bell', 'behind', 'batter', '38', 'work', 'wooden', 'wicker', 'watermelon', 'washington', 'very tall', 'typing', 'tank top', 't', 'surfer', 'snowy', 'sausage', 'red and green', 'phones', 'obama', 'nighttime', 'moving', 'ladder', 'hats', 'german shepherd', 'full', 'foil', 'fireplace', 'cross country', 'chihuahua', 'chicago', 'catching', 'c', '55', 'yellow and red', 'working', 'white and black', 'vertical', 'vanilla', 'traveling', 'towels', 'tiger', 'stuffed animals', 'stick', 'south', 'sad', 'red sox', 'potatoes', 'playing baseball', 'pigeon', 'orioles', 'one on right', 'museum', 'medium', 'mask', 'magnets', 'little', 'horns', 'hair dryer', 'foreground', 'eggs', 'east', 'daisy', 'cumulus', 'cone', 'commercial', 'ceiling', 'cargo', 'bun', 'bucket', 'bar', 'women', 'white and brown', 'waves', 'united states', 'twin', 'tray', 'transportation', 'scooter', 'sandwiches', 'roman numerals', 'roman', 'pasta', 'navy', 'lion', 'library', 'laptops', 'high', 'harley', 'garbage', 'flags', 'cleaning', 'cats', 'butterfly', 'butter', 'bus stop', 'bulldog', 'basil', 'apron', '60', 'vest', 'tail', 'swinging', 'sweater', 'subway', 'station', 'stars', 'smile', 'shrimp', 'shallow', 'runway', 'playing game', 'pineapple', 'pickles', 'pelican', 'peace', 'party', 'outdoor', 'on street', 'microphone', 'harley davidson', 'green and yellow', 'glazed', 'europe', 'driving', 'cookies', 'ceramic', 'cart', 'calico', 'bikini', '32', '10 feet', 'yellow and black', 'wild', 'uphill', 'tusks', 'tall', 'steak', 'sony', 'smiling', 'serving', 'sauce', 'railing', 'pork', 'polka dot', 'pigeons', 'pickle', 'parked', 'on tower', 'mushrooms', 'lots', 'leash', 'handle', 'halloween', 'hair', 'grill', 'golden retriever', 'goat', 'french fries', 'forward', 'egg', 'crane', 'cleats', 'cherry', 'chandelier', 'chain', 'camouflage', 'british airways', 'barn', 'bags', '45', 'x', 'west', 'wave', 'watching tv', 'wagon', 'vases', 'straight', 'store', 'soccer ball', 'smoothie', 'selfie', 'racing', 'pizza cutter', 'pig', 'pier', 'piano', 'oil', 'nokia', 'modern', 'laying', 'kids', 'gothic', 'germany', 'garage', 'finch', 'empty', 'desert', 'deer', 'corn', 'cook', 'cones', 'circles', 'catching frisbee', 'candy', 'california', 'black and yellow', 'beard', 'barbed wire', 'army', 'all', 'adult', '33', '26', 'wires', 'water bottle', 'washington dc', 'waiting', 'toothbrushes', 'toaster oven', 'taxi', 'tag', 'suv', 'string', 'stool', 'setting', 'santa', 'power lines', 'poodle', 'pilot', 'owner', 'one on left', 'on building', 'italian', 'hungry', 'harness', 'half', 'france', 'fell', 'emirates', 'dry', 'dirt bike', 'controller', 'can', 'bull', 'british', 'bowling', 'bib', 'behind fence', 'baseball field', 'australia', 'asphalt', 'animals', '44', '29', '2013', '150', 'yellow and white', 'woods', 'volleyball', 'vegetable', 'traffic light', 'traffic', 'throwing', 'thin', 'swan', 'skull', 'skier', 'ship', 'san francisco', 'rural', 'polka dots', 'pitching', 'panda', 'out', 'nintendo', 'mozzarella', 'maple', 'man on right', 'man on left', 'm', 'lilies', 'kite flying', 'in field', 'ice', 'hospital', 'farm', 'do not enter', 'dark', 'daisies', 'curly', 'cupcake', 'cucumber', 'corner', 'clock tower', 'chips', 'cheesecake', 'chairs', 'center', 'cardboard', 'business'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfX_W-R74nJH",
        "colab_type": "text"
      },
      "source": [
        "### Build Vanilla Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_4z0GKrA4Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_model(img_input):\n",
        "  x = Dense(1024, activation='tanh', input_dim = 4096)(img_input)\n",
        "  return x"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM29KNZPBCMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def qs_model(qs_input, num_words, embedding_dim, dropout_rate):\n",
        "  x = Embedding(len(word_index), embedding_dim, input_length=SEQ_LENGTH, #len(word_index)+1\n",
        "          weights=[embedding_matrix],      trainable = False)(qs_input)#weights=[embedding_matrix],\n",
        "  x = LSTM(units=512, return_sequences=True, input_shape= (None,embedding_dim))(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = LSTM(units=512, return_sequences=False)(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(1024, activation='tanh')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP_NNUBE4uoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vanilla(num_classes, dropout_rate, num_words, embedding_dim):\n",
        "  qs_input = Input(shape=( SEQ_LENGTH ,))#train_X_seqs.shape[1]\n",
        "  img_input = Input(shape=(4096,))\n",
        "\n",
        "  CNN_model = img_model(img_input)\n",
        "  LSTM_model = qs_model(qs_input, num_words, embedding_dim, dropout_rate)\n",
        "\n",
        "  x = Multiply()([CNN_model, LSTM_model])\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(1000, activation='tanh')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  output = Dense(num_classes-1, activation='softmax')(x)\n",
        "  \n",
        "  model = Model(inputs= [qs_input, img_input], outputs= output)\n",
        "  return model"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH-EWGFhw8lo",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_W1j71wQaJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "np.random.seed(123)\n",
        "python_random.seed(123)\n",
        "tf.random.set_seed(1234)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv5Srzj67DQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size=215359\n",
        "val_size=121512\n",
        "#215359\n",
        "#121512\n",
        "\n",
        "train_X_seqs_final=train_X_seqs[0:train_size]\n",
        "train_X_ims_final=train_X_ims[0:train_size]\n",
        "train_Y_final=train_Y[0:train_size]\n",
        "\n",
        "val_X_seqs_final=val_X_seqs[0:val_size]\n",
        "val_X_ims_final=val_X_ims[0:val_size]\n",
        "val_Y_final=val_Y[0:val_size]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aY0WN5YBMxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "12e7e5e2-fd73-45ae-f797-861ff9f23c7f"
      },
      "source": [
        "n_epochs=30\n",
        "b_size=500\n",
        "steps_per_epoch = int( np.ceil(train_X_seqs_final.shape[0] / b_size) )\n",
        "learning_rate_decay_every=50000 #300\n",
        "in_learning_rate=3e-4\n",
        "\n",
        "initializer = tf.keras.initializers.RandomUniform(minval=-0.08, maxval=0.08)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cc76600ccc05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_seqs_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlearning_rate_decay_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m \u001b[0;31m#300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0min_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJRSrSb9SdAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X_seqs=None\n",
        "train_X_ims=None\n",
        "train_Y=None\n",
        "val_X_seqs=None\n",
        "val_X_ims=None\n",
        "val_Y=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq1S0ZY4KwKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#uniform(-0.08, 0.08)\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=in_learning_rate,#1e-3\n",
        "    decay_steps=learning_rate_decay_every,\n",
        "    # decay_rate=math.exp(math.log(0.1)/learning_rate_decay_every/steps_per_epoch))#0.9\n",
        "    decay_rate = 0.99997592083)\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPzh3ppFMxO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bEjAHs_NzRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt=tf.keras.optimizers.RMSprop(lr=0.0004)#, rho=0.99, epsilon=1e-08, decay=300\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM2sdG2KC-HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt=tf.keras.optimizers.RMSprop()#lr=0.00004, rho=0.99, epsilon=1e-08, decay=300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr7Gy0FzZJPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt=tf.keras.optimizers.Adadelta(lr=1)#lr=0.00004, rho=0.99, epsilon=1e-08, decay=300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJqRDTTHw_eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Train():\n",
        "  checkpoint = ModelCheckpoint('model.h5', save_best_only=True)\n",
        "\n",
        "  earlystop_callback = EarlyStopping(\n",
        "  monitor='val_loss', min_delta=0.0001,\n",
        "  patience=10)\n",
        "\n",
        "  model = vanilla(NUM_OF_CLASSES, DROPOUT_RATE, len(word_index)+1, EMBEDDING_DIM)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  history = model.fit([train_X_seqs_final,train_X_ims_final] ,\n",
        "                      train_Y_final, \n",
        "                      epochs = n_epochs, \n",
        "                      batch_size = b_size#,\n",
        "                      #callbacks=[earlystop_callback], \n",
        "                      # callbacks = [checkpoint],\n",
        "                      # validation_data=([val_X_seqs_final,val_X_ims_final], val_Y_final) \n",
        "                      \n",
        "                      )#shuffle=True\n",
        "  return history, model"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2sPcer6Biey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7713a59d-fafd-4c81-912e-854c3b3ee4e6"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "history, model = Train()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 26)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 26, 300)      3780600     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 26, 512)      1665024     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 26, 512)      0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 512)          2099200     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 4096)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         4195328     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         525312      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 1024)         0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1000)         1025000     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1000)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 999)          999999      dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,290,463\n",
            "Trainable params: 10,509,863\n",
            "Non-trainable params: 3,780,600\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "431/431 [==============================] - 43s 100ms/step - loss: 3.4190 - accuracy: 0.2929\n",
            "Epoch 2/30\n",
            "431/431 [==============================] - 46s 107ms/step - loss: 2.7547 - accuracy: 0.3302\n",
            "Epoch 3/30\n",
            "431/431 [==============================] - 50s 115ms/step - loss: 2.5449 - accuracy: 0.3570\n",
            "Epoch 4/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 2.4012 - accuracy: 0.3773\n",
            "Epoch 5/30\n",
            "431/431 [==============================] - 49s 113ms/step - loss: 2.2960 - accuracy: 0.3936\n",
            "Epoch 6/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 2.2173 - accuracy: 0.4100\n",
            "Epoch 7/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 2.1611 - accuracy: 0.4195\n",
            "Epoch 8/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 2.1160 - accuracy: 0.4277\n",
            "Epoch 9/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 2.0768 - accuracy: 0.4355\n",
            "Epoch 10/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 2.0449 - accuracy: 0.4413\n",
            "Epoch 11/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 2.0165 - accuracy: 0.4460\n",
            "Epoch 12/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.9908 - accuracy: 0.4503\n",
            "Epoch 13/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.9678 - accuracy: 0.4568\n",
            "Epoch 14/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.9505 - accuracy: 0.4599\n",
            "Epoch 15/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.9314 - accuracy: 0.4653\n",
            "Epoch 16/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.9122 - accuracy: 0.4700\n",
            "Epoch 17/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8972 - accuracy: 0.4738\n",
            "Epoch 18/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8822 - accuracy: 0.4764\n",
            "Epoch 19/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8690 - accuracy: 0.4803\n",
            "Epoch 20/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8535 - accuracy: 0.4855\n",
            "Epoch 21/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8387 - accuracy: 0.4895\n",
            "Epoch 22/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8253 - accuracy: 0.4946\n",
            "Epoch 23/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8120 - accuracy: 0.4987\n",
            "Epoch 24/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.8018 - accuracy: 0.5018\n",
            "Epoch 25/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.7877 - accuracy: 0.5066\n",
            "Epoch 26/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.7743 - accuracy: 0.5108\n",
            "Epoch 27/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.7604 - accuracy: 0.5153\n",
            "Epoch 28/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.7483 - accuracy: 0.5196\n",
            "Epoch 29/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.7355 - accuracy: 0.5239\n",
            "Epoch 30/30\n",
            "431/431 [==============================] - 48s 112ms/step - loss: 1.7248 - accuracy: 0.5280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l7qqvrlOKGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "4c731c66-886c-498c-d1fe-89c99ae9d39e"
      },
      "source": [
        "plot_accuracy_loss(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TpkEEXm1BYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05327f27-e4e9-4060-e198-72c9ab085fd9"
      },
      "source": [
        "def Evaluation(model):\n",
        "  results = model.evaluate([val_X_seqs_final,val_X_ims_final], val_Y_final, batch_size=300)\n",
        "  print('val loss, val acc:', results)\n",
        "Evaluation(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "406/406 [==============================] - 11s 26ms/step - loss: 3.2440 - accuracy: 0.4090\n",
            "val loss, val acc: [3.2440288066864014, 0.4090377986431122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_CMHFB6WIwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(BASE_PATH_parssoft+'model_30ep_all.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou-AUdbiWHgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = []\n",
        "\n",
        "p = model.predict([val_X_seqs_final,val_X_ims_final],batch_size=64)\n",
        "\n",
        "for q in range(len(val_q_ids)):\n",
        "  ans=indextoanswer[p[q].argmax(axis=-1)]\n",
        "  q_id=val_q_ids[q]\n",
        "  result.append({u'answer': ans, u'question_id': q_id})\n",
        "\n",
        "  # if q%50000==0 :print(q)\n",
        "\n",
        "print('Saving result...')\n",
        "my_list = list(result)\n",
        "dd = json.dump(my_list,open(BASE_PATH_parssoft2+'result.json','w'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLoOfRTpB9EW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6838b9a6-5e94-42fe-c8cf-02cf00bc855c"
      },
      "source": [
        "!git clone https://github.com/GT-Vision-Lab/VQA.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'VQA'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 1.74 MiB | 4.03 MiB/s, done.\n",
            "Resolving deltas: 100% (124/124), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZK4-WLJDmk3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "41dc7db7-3a81-459c-e76b-8f7a7f2a666e"
      },
      "source": [
        "!git clone https://github.com/ntusteeian/VQA_evaluation.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'VQA_evaluation'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects:  10% (1/10)\u001b[K\rremote: Counting objects:  20% (2/10)\u001b[K\rremote: Counting objects:  30% (3/10)\u001b[K\rremote: Counting objects:  40% (4/10)\u001b[K\rremote: Counting objects:  50% (5/10)\u001b[K\rremote: Counting objects:  60% (6/10)\u001b[K\rremote: Counting objects:  70% (7/10)\u001b[K\rremote: Counting objects:  80% (8/10)\u001b[K\rremote: Counting objects:  90% (9/10)\u001b[K\rremote: Counting objects: 100% (10/10)\u001b[K\rremote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects:  10% (1/10)\u001b[K\rremote: Compressing objects:  20% (2/10)\u001b[K\rremote: Compressing objects:  30% (3/10)\u001b[K\rremote: Compressing objects:  40% (4/10)\u001b[K\rremote: Compressing objects:  50% (5/10)\u001b[K\rremote: Compressing objects:  60% (6/10)\u001b[K\rremote: Compressing objects:  70% (7/10)\u001b[K\rremote: Compressing objects:  80% (8/10)\u001b[K\rremote: Compressing objects:  90% (9/10)\u001b[K\rremote: Compressing objects: 100% (10/10)\u001b[K\rremote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "Receiving objects:   0% (1/301)   \rReceiving objects:   1% (4/301)   \rReceiving objects:   2% (7/301)   \rReceiving objects:   3% (10/301)   \rReceiving objects:   4% (13/301)   \rReceiving objects:   5% (16/301)   \rReceiving objects:   6% (19/301)   \rReceiving objects:   7% (22/301)   \rReceiving objects:   8% (25/301)   \rReceiving objects:   9% (28/301)   \rReceiving objects:  10% (31/301)   \rReceiving objects:  11% (34/301)   \rReceiving objects:  12% (37/301)   \rReceiving objects:  13% (40/301)   \rReceiving objects:  14% (43/301)   \rReceiving objects:  15% (46/301)   \rReceiving objects:  16% (49/301)   \rReceiving objects:  17% (52/301)   \rReceiving objects:  18% (55/301)   \rReceiving objects:  19% (58/301)   \rReceiving objects:  20% (61/301)   \rReceiving objects:  21% (64/301)   \rReceiving objects:  22% (67/301)   \rReceiving objects:  23% (70/301)   \rReceiving objects:  24% (73/301)   \rReceiving objects:  25% (76/301)   \rReceiving objects:  26% (79/301)   \rReceiving objects:  27% (82/301)   \rReceiving objects:  28% (85/301)   \rReceiving objects:  29% (88/301)   \rremote: Total 301 (delta 0), reused 5 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects:  30% (91/301)   \rReceiving objects:  31% (94/301)   \rReceiving objects:  32% (97/301)   \rReceiving objects:  33% (100/301)   \rReceiving objects:  34% (103/301)   \rReceiving objects:  35% (106/301)   \rReceiving objects:  36% (109/301)   \rReceiving objects:  37% (112/301)   \rReceiving objects:  38% (115/301)   \rReceiving objects:  39% (118/301)   \rReceiving objects:  40% (121/301)   \rReceiving objects:  41% (124/301)   \rReceiving objects:  42% (127/301)   \rReceiving objects:  43% (130/301)   \rReceiving objects:  44% (133/301)   \rReceiving objects:  45% (136/301)   \rReceiving objects:  46% (139/301)   \rReceiving objects:  47% (142/301)   \rReceiving objects:  48% (145/301)   \rReceiving objects:  49% (148/301)   \rReceiving objects:  50% (151/301)   \rReceiving objects:  51% (154/301)   \rReceiving objects:  52% (157/301)   \rReceiving objects:  53% (160/301)   \rReceiving objects:  54% (163/301)   \rReceiving objects:  55% (166/301)   \rReceiving objects:  56% (169/301)   \rReceiving objects:  57% (172/301)   \rReceiving objects:  58% (175/301)   \rReceiving objects:  59% (178/301)   \rReceiving objects:  60% (181/301)   \rReceiving objects:  61% (184/301)   \rReceiving objects:  62% (187/301)   \rReceiving objects:  63% (190/301)   \rReceiving objects:  64% (193/301)   \rReceiving objects:  65% (196/301)   \rReceiving objects:  66% (199/301)   \rReceiving objects:  67% (202/301)   \rReceiving objects:  68% (205/301)   \rReceiving objects:  69% (208/301)   \rReceiving objects:  70% (211/301)   \rReceiving objects:  71% (214/301)   \rReceiving objects:  72% (217/301)   \rReceiving objects:  73% (220/301)   \rReceiving objects:  74% (223/301)   \rReceiving objects:  75% (226/301)   \rReceiving objects:  76% (229/301)   \rReceiving objects:  77% (232/301)   \rReceiving objects:  78% (235/301)   \rReceiving objects:  79% (238/301)   \rReceiving objects:  80% (241/301)   \rReceiving objects:  81% (244/301)   \rReceiving objects:  82% (247/301)   \rReceiving objects:  83% (250/301)   \rReceiving objects:  84% (253/301)   \rReceiving objects:  85% (256/301)   \rReceiving objects:  86% (259/301)   \rReceiving objects:  87% (262/301)   \rReceiving objects:  88% (265/301)   \rReceiving objects:  89% (268/301)   \rReceiving objects:  90% (271/301)   \rReceiving objects:  91% (274/301)   \rReceiving objects:  92% (277/301)   \rReceiving objects:  93% (280/301)   \rReceiving objects:  94% (283/301)   \rReceiving objects:  95% (286/301)   \rReceiving objects:  96% (289/301)   \rReceiving objects:  97% (292/301)   \rReceiving objects:  98% (295/301)   \rReceiving objects:  99% (298/301)   \rReceiving objects: 100% (301/301)   \rReceiving objects: 100% (301/301), 1.75 MiB | 15.86 MiB/s, done.\n",
            "Resolving deltas:   0% (0/124)   \rResolving deltas:  10% (13/124)   \rResolving deltas:  15% (19/124)   \rResolving deltas:  18% (23/124)   \rResolving deltas:  23% (29/124)   \rResolving deltas:  30% (38/124)   \rResolving deltas:  41% (51/124)   \rResolving deltas:  50% (63/124)   \rResolving deltas:  54% (67/124)   \rResolving deltas:  55% (69/124)   \rResolving deltas:  58% (73/124)   \rResolving deltas:  68% (85/124)   \rResolving deltas:  70% (88/124)   \rResolving deltas:  81% (101/124)   \rResolving deltas:  85% (106/124)   \rResolving deltas:  88% (110/124)   \rResolving deltas:  97% (121/124)   \rResolving deltas:  99% (123/124)   \rResolving deltas: 100% (124/124)   \rResolving deltas: 100% (124/124), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZwLZgluivjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48804dd4-557b-4593-9dc9-8013d6598fd0"
      },
      "source": [
        "# coding: utf-8\n",
        "\n",
        "import sys\n",
        "dataDir = '/content/drive/My Drive/parssoftco_PVQA2'\n",
        "sys.path.insert(0, '/content/drive/My Drive/parssoftco_PVQA/')\n",
        "from vqaTools.vqa import VQA\n",
        "from vqaEvaluation.vqaEval import VQAEval\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io as io\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "\n",
        "# set up file names and paths\n",
        "versionType ='' # this should be '' when using VQA v2.0 dataset\n",
        "taskType    ='OpenEnded' # 'OpenEnded' only for v2.0. 'OpenEnded' or 'MultipleChoice' for v1.0\n",
        "dataType    ='mscoco'  # 'mscoco' only for v1.0. 'mscoco' for real and 'abstract_v002' for abstract for v1.0. \n",
        "dataSubType ='val2014'\n",
        "annFile     ='%s/%s%s_%s_annotations.json'%(dataDir, versionType, dataType, dataSubType)\n",
        "quesFile    ='%s/%s%s_%s_%s_questions.json'%(dataDir, versionType, taskType, dataType, dataSubType)\n",
        "imgDir      ='%s/Images/%s/%s/' %(dataDir, dataType, dataSubType)\n",
        "fileTypes   = ['results', 'accuracy', 'evalQA', 'evalQuesType', 'evalAnsType']\n",
        "\n",
        "# An example result json file has been provided in './Results' folder.  \n",
        "\n",
        "[resFile, accuracyFile, evalQAFile, evalQuesTypeFile, evalAnsTypeFile] =['%s/result.json'%(dataDir) for fileType in fileTypes]\n",
        "# create vqa object and vqaRes object\n",
        "vqa = VQA(annFile, quesFile)\n",
        "vqaRes = vqa.loadRes(resFile, quesFile)\n",
        "\n",
        "# create vqaEval object by taking vqa and vqaRes\n",
        "vqaEval = VQAEval(vqa, vqaRes, n=2)   #n is precision of accuracy (number of places after decimal), default is 2\n",
        "\n",
        "# evaluate results\n",
        "\"\"\"\n",
        "If you have a list of question ids on which you would like to evaluate your results, pass it as a list to below function\n",
        "By default it uses all the question ids in annotation file\n",
        "\"\"\"\n",
        "vqaEval.evaluate() \n",
        "\n",
        "# print accuracies\n",
        "print (\"\\n\")\n",
        "print (\"Overall Accuracy is: %.02f\\n\" %(vqaEval.accuracy['overall']))\n",
        "print (\"Per Question Type Accuracy is the following:\")\n",
        "for quesType in vqaEval.accuracy['perQuestionType']:\n",
        "\tprint (\"%s : %.02f\" %(quesType, vqaEval.accuracy['perQuestionType'][quesType]))\n",
        "print (\"\\n\")\n",
        "print (\"Per Answer Type Accuracy is the following:\")\n",
        "for ansType in vqaEval.accuracy['perAnswerType']:\n",
        "\tprint (\"%s : %.02f\" %(ansType, vqaEval.accuracy['perAnswerType'][ansType]))\n",
        "print (\"\\n\")\n",
        "# demo how to use evalQA to retrieve low score result\n",
        "evals = [quesId for quesId in vqaEval.evalQA if vqaEval.evalQA[quesId]<35]   #35 is per question percentage accuracy\n",
        "if len(evals) > 0:\n",
        "\tprint ('ground truth answers')\n",
        "\trandomEval = random.choice(evals)\n",
        "\trandomAnn = vqa.loadQA(randomEval)\n",
        "\tvqa.showQA(randomAnn)\n",
        "\n",
        "\tprint ('\\n')\n",
        "\tprint ('generated answer (accuracy %.02f)'%(vqaEval.evalQA[randomEval]))\n",
        "\t# ann = vqaRes.loadQA(randomEval)[0]\n",
        "\t# print (\"Answer:   %s\\n\" %(ann['answer']))\n",
        "\n",
        "\t# imgId = randomAnn[0]['image_id']\n",
        "\t# imgFilename = 'COCO_' + dataSubType + '_'+ str(imgId).zfill(12) + '.jpg'\n",
        "\t# if os.path.isfile(imgDir + imgFilename):\n",
        "\t# \tI = io.imread(imgDir + imgFilename)\n",
        "\t# \tplt.imshow(I)\n",
        "\t# \tplt.axis('off')\n",
        "\t# \tplt.show()\n",
        "\n",
        "# plot accuracy for various question types\n",
        "plt.bar(range(len(vqaEval.accuracy['perQuestionType'])), vqaEval.accuracy['perQuestionType'].values(), align='center')\n",
        "plt.xticks(range(len(vqaEval.accuracy['perQuestionType'])), vqaEval.accuracy['perQuestionType'].keys(), rotation='0',fontsize=10)\n",
        "plt.title('Per Question Type Accuracy', fontsize=10)\n",
        "plt.xlabel('Question Types', fontsize=10)\n",
        "plt.ylabel('Accuracy', fontsize=10)\n",
        "plt.show()\n",
        "\n",
        "# save evaluation results to ./Results folder\n",
        "json.dump(vqaEval.accuracy,     open(accuracyFile,     'w'))\n",
        "json.dump(vqaEval.evalQA,       open(evalQAFile,       'w'))\n",
        "json.dump(vqaEval.evalQuesType, open(evalQuesTypeFile, 'w'))\n",
        "# json.dump(vqaEval.evalAnsType,  open(evalAnsTypeFile,  'w'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading VQA annotations and questions into memory...\n",
            "0:00:04.774469\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.33s)\n",
            "creating index...\n",
            "index created!\n",
            "computing accuracy\n",
            "Finshed Percent: [####################] 99% Done computing accuracy\n",
            "\n",
            "\n",
            "Overall Accuracy is: 47.37\n",
            "\n",
            "Per Question Type Accuracy is the following:\n",
            "what is the : 24.50\n",
            "is the : 73.23\n",
            "what : 26.13\n",
            "is this an : 76.83\n",
            "are there : 82.40\n",
            "what is in the : 22.59\n",
            "is it : 76.04\n",
            "what is : 18.09\n",
            "how many : 38.72\n",
            "is this : 73.85\n",
            "is there a : 89.55\n",
            "is the person : 73.95\n",
            "is this a : 74.67\n",
            "what color is the : 39.01\n",
            "how : 18.35\n",
            "do : 75.02\n",
            "how many people are in : 34.88\n",
            "why : 13.43\n",
            "are the : 73.77\n",
            "none of the above : 45.70\n",
            "are : 73.10\n",
            "does this : 77.49\n",
            "what is the person : 18.84\n",
            "what are : 23.79\n",
            "who is : 17.66\n",
            "what brand : 31.16\n",
            "has : 75.48\n",
            "what kind of : 27.25\n",
            "is the man : 77.35\n",
            "are they : 75.43\n",
            "what type of : 30.44\n",
            "is : 77.24\n",
            "is this person : 73.83\n",
            "what is the man : 24.35\n",
            "are these : 71.33\n",
            "how many people are : 37.50\n",
            "what is on the : 25.93\n",
            "is there : 84.02\n",
            "do you : 81.95\n",
            "what color are the : 39.87\n",
            "where is the : 16.63\n",
            "what time : 11.05\n",
            "does the : 78.32\n",
            "are there any : 73.98\n",
            "what room is : 45.66\n",
            "what sport is : 45.17\n",
            "is he : 78.76\n",
            "is the woman : 74.07\n",
            "which : 33.79\n",
            "what does the : 17.23\n",
            "what color : 26.75\n",
            "what is the name : 5.70\n",
            "where are the : 18.59\n",
            "was : 75.78\n",
            "what animal is : 20.23\n",
            "what is the color of the : 51.86\n",
            "what is the woman : 18.85\n",
            "could : 89.38\n",
            "what are the : 22.93\n",
            "what is this : 21.39\n",
            "can you : 75.88\n",
            "what number is : 2.21\n",
            "is that a : 74.71\n",
            "what color is : 28.10\n",
            "why is the : 13.40\n",
            "\n",
            "\n",
            "Per Answer Type Accuracy is the following:\n",
            "other : 27.73\n",
            "yes/no : 78.56\n",
            "number : 32.60\n",
            "\n",
            "\n",
            "ground truth answers\n",
            "Question: Where is the cat?\n",
            "Answer 1: pillow\n",
            "Answer 2: on chair\n",
            "Answer 3: couch\n",
            "Answer 4: on couch\n",
            "Answer 5: on couch\n",
            "Answer 6: couch\n",
            "Answer 7: couch\n",
            "Answer 8: on couch\n",
            "Answer 9: on sofa\n",
            "Answer 10: couch\n",
            "\n",
            "\n",
            "generated answer (accuracy 0.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UgYacz5IKR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "556c66f6-dce0-4db1-fb95-70ee04cbd5d0"
      },
      "source": [
        "a=[1,2,3]\n",
        "a[:2]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HbfgCxpGUN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "680df40e-34ee-418b-c287-058720b6e571"
      },
      "source": [
        "!python /content/drive/My\\ Drive/parssoftco_PVQA/vqaEvalDemo.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading VQA annotations and questions into memory...\n",
            "0:00:01.991607\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/My Drive/parssoftco_PVQA/vqaEvalDemo.py\", line 29, in <module>\n",
            "    vqaRes = vqa.loadRes(resFile, quesFile)\n",
            "  File \"/content/drive/My Drive/parssoftco_PVQA/vqaTools/vqa.py\", line 159, in loadRes\n",
            "    assert type(anns) == list, 'results is not an array of objects'\n",
            "AssertionError: results is not an array of objects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1sex9ZymQJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "9312777b-93cd-4475-e84f-6f475491e9ef"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save(BASE_PATH_parssoft+ 'model_alldata_30ep_eng_rmslrdecay.h5', overwrite=True)  # creates a HDF5 file 'my_model.h5'\n",
        "del model  # deletes the existing model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "# model = load_model('my_model.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-220-37f65479cbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH_parssoft\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'model_alldata_30ep_eng_rmslrdecay.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# creates a HDF5 file 'my_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;31m# deletes the existing model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \"\"\"\n\u001b[1;32m   1051\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1052\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    133\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    134\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 135\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    123\u001b[0m     if (include_optimizer and model.optimizer and\n\u001b[1;32m    124\u001b[0m         not isinstance(model.optimizer, optimizers.TFOptimizer)):\n\u001b[0;32m--> 125\u001b[0;31m       \u001b[0msave_optimizer_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_optimizer_weights_to_hdf5_group\u001b[0;34m(hdf5_group, optimizer)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m       param_dset = weights_group.create_dataset(\n\u001b[0;32m--> 593\u001b[0;31m           name, val.shape, dtype=val.dtype)\n\u001b[0m\u001b[1;32m    594\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHLObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSoftLink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.link\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to create link (name already exists)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MzayYUlwLWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtaA37jxEGaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy_loss(history):\n",
        "  acc      = history.history[     'accuracy' ]\n",
        "  val_acc  = history.history[ 'val_accuracy' ]\n",
        "  loss     = history.history[    'loss' ]\n",
        "  val_loss = history.history['val_loss' ]\n",
        "\n",
        "  epochs   = range(len(acc))\n",
        "\n",
        "  plt.plot  ( epochs,     acc, label='train_acc' )\n",
        "  plt.plot  ( epochs, val_acc, label='val_acc' )\n",
        "  plt.title ('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.savefig(BASE_PATH + 'Training and validation accuracy.jpg')\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot  ( epochs,     loss, label='train_loss' )\n",
        "  plt.plot  ( epochs, val_loss, label='val_loss' )\n",
        "  plt.title ('Training and validation loss'   )\n",
        "  plt.legend()\n",
        "  plt.savefig(BASE_PATH + 'Training and validation loss.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4OteN2u22vj",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQtv4GmfkUNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eab172c6-8e3f-45cd-8336-97efbd7a00d7"
      },
      "source": [
        "# Download the VQA Questions from http://www.visualqa.org/download.html\n",
        "import json\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "'''\n",
        "Put the VQA data into single json file, where [[Question_id, Image_id, Question, multipleChoice_answer, Answer] ... ]\n",
        "'''\n",
        "\n",
        "train = []\n",
        "test = []\n",
        "imdir='%s/COCO_%s_%012d.jpg'\n",
        "\n",
        "\n",
        "print('Loading annotations and questions...')\n",
        "train_anno = json.load(open(ANNOTATION_TRAIN_PATH, 'r'))\n",
        "val_anno = json.load(open(ANNOTATION_VAL_PATH, 'r'))\n",
        "\n",
        "train_ques = json.load(open(QUESTION_TRAIN_PATH, 'r'))\n",
        "val_ques = json.load(open(QUESTION_VAL_PATH, 'r'))\n",
        "\n",
        "subtype = 'train2014'\n",
        "for i in range(len(train_anno['annotations'])):\n",
        "    ans = train_anno['annotations'][i]['multiple_choice_answer']\n",
        "    question_id = train_anno['annotations'][i]['question_id']\n",
        "    image_path = imdir%(subtype, subtype, train_anno['annotations'][i]['image_id'])\n",
        "\n",
        "    question = train_ques['questions'][i]['question']\n",
        "    mc_ans = train_ques['questions'][i]['question']\n",
        "\n",
        "    train.append({'ques_id': question_id, 'img_path': image_path, 'question': question, 'MC_ans': mc_ans, 'ans': ans})\n",
        "\n",
        "subtype = 'val2014'\n",
        "for i in range(len(val_anno['annotations'])):\n",
        "    ans = val_anno['annotations'][i]['multiple_choice_answer']\n",
        "    question_id = val_anno['annotations'][i]['question_id']\n",
        "    image_path = imdir%(subtype, subtype, val_anno['annotations'][i]['image_id'])\n",
        "\n",
        "    question = val_ques['questions'][i]['question']\n",
        "    mc_ans = val_ques['questions'][i]['question']\n",
        "\n",
        "    test.append({'ques_id': question_id, 'img_path': image_path, 'question': question, 'MC_ans': mc_ans, 'ans': ans})\n",
        "\n",
        "\n",
        "print('Training sample %d, Testing sample %d...' %(len(train), len(test)))\n",
        "\n",
        "json.dump(train, open('vqa_raw_train.json', 'w'))\n",
        "json.dump(test, open('vqa_raw_test.json', 'w'))\n",
        "\n",
        "\n",
        "# !cp /content/vqa_raw_train.json /content/drive/My\\ Drive/parssoftco_PVQA/vqa_raw_train.json\n",
        "# !cp /content/vqa_raw_test.json /content/drive/My\\ Drive/parssoftco_PVQA/vqa_raw_test.json\n",
        "\n",
        "\n",
        "def get_top_answers(imgs, params):\n",
        "  counts = {}\n",
        "  for img in imgs:\n",
        "    ans = img['ans']\n",
        "    counts[ans] = counts.get(ans, 0) + 1\n",
        "  cw = sorted([(count,w) for w,count in counts.items()], reverse=True)\n",
        "  vocab = []\n",
        "  for i in range(params):\n",
        "      vocab.append(cw[i][1])\n",
        "  return vocab[:params]\n",
        "\n",
        "\n",
        "def filter_question(imgs, atoi):\n",
        "    new_imgs = []\n",
        "    for i, img in enumerate(imgs):\n",
        "        if atoi.get(img['ans'],len(atoi)+1) != len(atoi)+1:\n",
        "            new_imgs.append(img)\n",
        "\n",
        "    print('question number reduce from %d to %d '%(len(imgs), len(new_imgs)))\n",
        "    return new_imgs\n",
        "imgs_train = json.load(open('vqa_raw_train.json', 'r'))\n",
        "imgs_test = json.load(open('vqa_raw_test.json', 'r'))\n",
        "\n",
        "# get top answers\n",
        "top_ans = get_top_answers(imgs_train, 999)\n",
        "atoi = {w:i+1 for i,w in enumerate(top_ans)}\n",
        "itoa = {i+1:w for i,w in enumerate(top_ans)}\n",
        "\n",
        "# filter question, which isn't in the top answers.\n",
        "imgs_train = filter_question(imgs_train, atoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading annotations and questions...\n",
            "Training sample 248349, Testing sample 121512...\n",
            "question number reduce from 248349 to 215359 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdUAuZOf8XoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fb0f5e15-2dc2-43c3-f1a5-be31cd3ee5c8"
      },
      "source": [
        "q = json.load(open('vqa_raw_train.json', 'r'))\n",
        "print(q[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'ques_id': 4870250, 'img_path': 'train2014/COCO_train2014_000000487025.jpg', 'question': 'What shape is the bench seat?', 'MC_ans': 'What shape is the bench seat?', 'ans': 'curved'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKyHgjE0DYsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3032421a-f44e-482f-f8c4-f226d3eea6d0"
      },
      "source": [
        "imgs_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MC_ans': 'Is there a shadow?',\n",
              " 'ans': 'yes',\n",
              " 'img_path': 'train2014/COCO_train2014_000000487025.jpg',\n",
              " 'ques_id': 4870251,\n",
              " 'question': 'Is there a shadow?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PSKiHFT8lT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Ehj85B_wi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhdLAVyp83M4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "65725d3e-9aaa-4e56-80fb-78e4e6243bab"
      },
      "source": [
        "# img_data = h5py.File(data_img)\n",
        "ques_data = h5py.File('data_prepro.h5')\n",
        "\n",
        "# img_data = np.array(img_data['images_train'])\n",
        "\n",
        "# NOTE should've consturcted one-hots using exhausitve list of answers, cause some answers may not be in dataset\n",
        "# To temporarily rectify this, all those answer indices is set to 1 in validation set\n",
        "train_y = to_categorical(ques_data['answers'])[:, :]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StgYdEhCBD3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4e1e4fa-7acf-4464-dd1a-bf671b7d7f5c"
      },
      "source": [
        "train_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(215359, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Vdvp8lCkNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E922I1NCIav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e=[]\n",
        "for s in ques_data['answers']:\n",
        "  e.append(s)\n",
        "set(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oghMBGvBOl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5881925-8de4-4180-f2e3-a040bc6ada26"
      },
      "source": [
        "e=[]\n",
        "for s in ques_data['answers']:\n",
        "  e.append(s)\n",
        "set(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 618,\n",
              " 619,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 625,\n",
              " 626,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 630,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 638,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 647,\n",
              " 648,\n",
              " 649,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 657,\n",
              " 658,\n",
              " 659,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 665,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 674,\n",
              " 675,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 684,\n",
              " 685,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 693,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 717,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 762,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 786,\n",
              " 787,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 800,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 809,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 817,\n",
              " 818,\n",
              " 819,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 825,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 836,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 850,\n",
              " 851,\n",
              " 852,\n",
              " 853,\n",
              " 854,\n",
              " 855,\n",
              " 856,\n",
              " 857,\n",
              " 858,\n",
              " 859,\n",
              " 860,\n",
              " 861,\n",
              " 862,\n",
              " 863,\n",
              " 864,\n",
              " 865,\n",
              " 866,\n",
              " 867,\n",
              " 868,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 872,\n",
              " 873,\n",
              " 874,\n",
              " 875,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 884,\n",
              " 885,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 893,\n",
              " 894,\n",
              " 895,\n",
              " 896,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 901,\n",
              " 902,\n",
              " 903,\n",
              " 904,\n",
              " 905,\n",
              " 906,\n",
              " 907,\n",
              " 908,\n",
              " 909,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 913,\n",
              " 914,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 918,\n",
              " 919,\n",
              " 920,\n",
              " 921,\n",
              " 922,\n",
              " 923,\n",
              " 924,\n",
              " 925,\n",
              " 926,\n",
              " 927,\n",
              " 928,\n",
              " 929,\n",
              " 930,\n",
              " 931,\n",
              " 932,\n",
              " 933,\n",
              " 934,\n",
              " 935,\n",
              " 936,\n",
              " 937,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 942,\n",
              " 943,\n",
              " 944,\n",
              " 945,\n",
              " 946,\n",
              " 947,\n",
              " 948,\n",
              " 949,\n",
              " 950,\n",
              " 951,\n",
              " 952,\n",
              " 953,\n",
              " 954,\n",
              " 955,\n",
              " 956,\n",
              " 957,\n",
              " 958,\n",
              " 959,\n",
              " 960,\n",
              " 961,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 967,\n",
              " 968,\n",
              " 969,\n",
              " 970,\n",
              " 971,\n",
              " 972,\n",
              " 973,\n",
              " 974,\n",
              " 975,\n",
              " 976,\n",
              " 977,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 983,\n",
              " 984,\n",
              " 985,\n",
              " 986,\n",
              " 987,\n",
              " 988,\n",
              " 989,\n",
              " 990,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 999}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}